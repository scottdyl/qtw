{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2year.arff', '3year.arff', '5year.arff', '4year.arff', '1year.arff']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "dir_files = [i for i in os.listdir(os.getcwd() + '/data') if os.path.isfile(join(os.getcwd() + '/data', i))]\n",
    "dir_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.5.0\n",
      "Keras Version: 2.5.0\n",
      "\n",
      "Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:24:02) \n",
      "[Clang 11.1.0 ]\n",
      "Pandas 1.3.4\n",
      "Scikit-Learn 1.0.1\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# What version of Python do you have?\n",
    "import sys\n",
    "\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tensorflow.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zl/4qqdwn7s6wv34lrr9sxt7tf40000gn/T/ipykernel_53300/2888193755.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrecords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mindx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#     temp_data = arff.loadarff(os.getcwd() + '/data/' +f)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "data_dict = {}\n",
    "full_df = pd.DataFrame()\n",
    "\n",
    "records = 0\n",
    "\n",
    "for indx, f in dir_files:\n",
    "    print(indx,f)\n",
    "#     temp_data = arff.loadarff(os.getcwd() + '/data/' +f)\n",
    "    \n",
    "#     temp_df = pd.DataFrame(temp_data[0])\n",
    "#     temp_df['year']=1\n",
    "#     print(temp_df)\n",
    "#     pd.DataFrame()\n",
    "#     print(temp_df.shape)\n",
    "#     data_dict.update({f:temp_df})\n",
    "#     full_df = pd.concat([full_df, temp_df])\n",
    "#     records += temp_df.shape[0]\n",
    "\n",
    "# print(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Attr1    Attr2     Attr3    Attr4     Attr5     Attr6     Attr7  \\\n",
      "0     0.088238  0.55472  0.011340  1.02050  -66.5200  0.342040  0.109490   \n",
      "1    -0.006202  0.48465  0.232980  1.59980    6.1825  0.000000 -0.006202   \n",
      "2     0.130240  0.22142  0.577510  3.60820  120.0400  0.187640  0.162120   \n",
      "3    -0.089951  0.88700  0.269270  1.52220  -55.9920 -0.073957 -0.089951   \n",
      "4     0.048179  0.55041  0.107650  1.24370  -22.9590  0.000000  0.059280   \n",
      "...        ...      ...       ...      ...       ...       ...       ...   \n",
      "5905  0.012898  0.70621  0.038857  1.17220  -18.9070  0.000000  0.013981   \n",
      "5906 -0.578050  0.96702 -0.800850  0.16576  -67.3650 -0.578050 -0.578050   \n",
      "5907 -0.179050  1.25530 -0.275990  0.74554 -120.4400 -0.179050 -0.154930   \n",
      "5908 -0.108860  0.74394  0.015449  1.08780  -17.0030 -0.108860 -0.109180   \n",
      "5909 -0.105370  0.53629 -0.045578  0.91478  -56.0680 -0.105370 -0.109940   \n",
      "\n",
      "        Attr8    Attr9    Attr10  ...    Attr57   Attr58    Attr59    Attr60  \\\n",
      "0     0.57752  1.08810  0.320360  ...  0.275430  0.91905  0.002024    7.2711   \n",
      "1     1.06340  1.27570  0.515350  ... -0.012035  1.00470  0.152220    6.0911   \n",
      "2     3.05900  1.14150  0.677310  ...  0.192290  0.87604  0.000000    8.7934   \n",
      "3     0.12740  1.27540  0.113000  ... -0.796020  0.59074  2.878700    7.6524   \n",
      "4     0.81682  1.51500  0.449590  ...  0.107160  0.77048  0.139380   10.1180   \n",
      "...       ...      ...       ...  ...       ...      ...       ...       ...   \n",
      "5905  0.41600  1.67680  0.293790  ...  0.043904  1.01220  1.259400   13.4720   \n",
      "5906 -0.40334  0.93979 -0.390040  ...  1.482000  1.06410 -0.018084  110.7200   \n",
      "5907 -0.26018  1.17490 -0.326590  ...  0.548240  0.85112 -0.522430    9.8526   \n",
      "5908  0.12531  0.84516  0.093224  ... -1.167700  1.18320  6.092400   13.8860   \n",
      "5909  0.86460  0.95040  0.463670  ... -0.227250  1.05220  0.003196    7.7332   \n",
      "\n",
      "       Attr61   Attr62  Attr63   Attr64  class  Year  \n",
      "0      4.7343  142.760  2.5568  3.25970   b'0'     4  \n",
      "1      3.2749  111.140  3.2841  3.37000   b'0'     4  \n",
      "2      2.9870   71.531  5.1027  5.61880   b'0'     4  \n",
      "3      3.3302  147.560  2.4735  5.92990   b'0'     4  \n",
      "4      4.0950  106.430  3.4294  3.36220   b'0'     4  \n",
      "...       ...      ...     ...      ...    ...   ...  \n",
      "5905  12.4320   49.117  7.4313  2.27990   b'1'     4  \n",
      "5906  44.7590   81.220  4.4940  5.13050   b'1'     4  \n",
      "5907   3.4892  207.870  1.7559  9.95270   b'1'     4  \n",
      "5908   6.0769   83.122  4.3911  0.95575   b'1'     4  \n",
      "5909   4.7174  136.850  2.6672  2.79270   b'1'     4  \n",
      "\n",
      "[5910 rows x 66 columns]\n"
     ]
    }
   ],
   "source": [
    "data_dict = {}\n",
    "full_df = pd.DataFrame()\n",
    "listy = []\n",
    "records = 0\n",
    "for indx, f in enumerate(sorted(dir_files)):\n",
    "    temp_data = arff.loadarff(os.getcwd() + '/data/' +f)\n",
    "    if indx\n",
    "    temp_df = pd.DataFrame(temp_data[0])\n",
    "    temp_df[\"Year\"] = indx\n",
    "    data_dict.update({f:temp_df})\n",
    "    full_df = pd.concat([full_df, temp_df])\n",
    "    records += temp_df.shape[0]\n",
    "\n",
    "print(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    5910\n",
       "Name: Year, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df[\"Year\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attr1</th>\n",
       "      <th>Attr2</th>\n",
       "      <th>Attr3</th>\n",
       "      <th>Attr4</th>\n",
       "      <th>Attr5</th>\n",
       "      <th>Attr6</th>\n",
       "      <th>Attr7</th>\n",
       "      <th>Attr8</th>\n",
       "      <th>Attr9</th>\n",
       "      <th>Attr10</th>\n",
       "      <th>...</th>\n",
       "      <th>Attr56</th>\n",
       "      <th>Attr57</th>\n",
       "      <th>Attr58</th>\n",
       "      <th>Attr59</th>\n",
       "      <th>Attr60</th>\n",
       "      <th>Attr61</th>\n",
       "      <th>Attr62</th>\n",
       "      <th>Attr63</th>\n",
       "      <th>Attr64</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.202350</td>\n",
       "      <td>0.46500</td>\n",
       "      <td>0.240380</td>\n",
       "      <td>1.5171</td>\n",
       "      <td>-14.547</td>\n",
       "      <td>0.510690</td>\n",
       "      <td>0.25366</td>\n",
       "      <td>0.91816</td>\n",
       "      <td>1.15190</td>\n",
       "      <td>0.42695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13184</td>\n",
       "      <td>0.473950</td>\n",
       "      <td>0.86816</td>\n",
       "      <td>0.00024</td>\n",
       "      <td>8.5487</td>\n",
       "      <td>5.16550</td>\n",
       "      <td>107.740</td>\n",
       "      <td>3.38790</td>\n",
       "      <td>5.3440</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.030073</td>\n",
       "      <td>0.59563</td>\n",
       "      <td>0.186680</td>\n",
       "      <td>1.3382</td>\n",
       "      <td>-37.859</td>\n",
       "      <td>-0.000319</td>\n",
       "      <td>0.04167</td>\n",
       "      <td>0.67890</td>\n",
       "      <td>0.32356</td>\n",
       "      <td>0.40437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12146</td>\n",
       "      <td>0.074369</td>\n",
       "      <td>0.87235</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.5264</td>\n",
       "      <td>0.63305</td>\n",
       "      <td>622.660</td>\n",
       "      <td>0.58619</td>\n",
       "      <td>1.2381</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.257860</td>\n",
       "      <td>0.29949</td>\n",
       "      <td>0.665190</td>\n",
       "      <td>3.2211</td>\n",
       "      <td>71.799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.31877</td>\n",
       "      <td>2.33200</td>\n",
       "      <td>1.67620</td>\n",
       "      <td>0.69841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16499</td>\n",
       "      <td>0.369210</td>\n",
       "      <td>0.81614</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.3325</td>\n",
       "      <td>3.19850</td>\n",
       "      <td>65.215</td>\n",
       "      <td>5.59690</td>\n",
       "      <td>47.4660</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.227160</td>\n",
       "      <td>0.67850</td>\n",
       "      <td>0.042784</td>\n",
       "      <td>1.0828</td>\n",
       "      <td>-88.212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.28505</td>\n",
       "      <td>0.47384</td>\n",
       "      <td>1.32410</td>\n",
       "      <td>0.32150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.29358</td>\n",
       "      <td>0.706570</td>\n",
       "      <td>0.78617</td>\n",
       "      <td>0.48456</td>\n",
       "      <td>5.2309</td>\n",
       "      <td>5.06750</td>\n",
       "      <td>142.460</td>\n",
       "      <td>2.56210</td>\n",
       "      <td>3.0066</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.085443</td>\n",
       "      <td>0.38039</td>\n",
       "      <td>0.359230</td>\n",
       "      <td>1.9444</td>\n",
       "      <td>21.731</td>\n",
       "      <td>0.187900</td>\n",
       "      <td>0.10823</td>\n",
       "      <td>1.37140</td>\n",
       "      <td>1.11260</td>\n",
       "      <td>0.52167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10124</td>\n",
       "      <td>0.163790</td>\n",
       "      <td>0.89876</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.7035</td>\n",
       "      <td>4.00200</td>\n",
       "      <td>89.058</td>\n",
       "      <td>4.09840</td>\n",
       "      <td>5.9874</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Attr1    Attr2     Attr3   Attr4   Attr5     Attr6    Attr7    Attr8  \\\n",
       "0  0.202350  0.46500  0.240380  1.5171 -14.547  0.510690  0.25366  0.91816   \n",
       "1  0.030073  0.59563  0.186680  1.3382 -37.859 -0.000319  0.04167  0.67890   \n",
       "2  0.257860  0.29949  0.665190  3.2211  71.799  0.000000  0.31877  2.33200   \n",
       "3  0.227160  0.67850  0.042784  1.0828 -88.212  0.000000  0.28505  0.47384   \n",
       "4  0.085443  0.38039  0.359230  1.9444  21.731  0.187900  0.10823  1.37140   \n",
       "\n",
       "     Attr9   Attr10  ...   Attr56    Attr57   Attr58   Attr59  Attr60  \\\n",
       "0  1.15190  0.42695  ...  0.13184  0.473950  0.86816  0.00024  8.5487   \n",
       "1  0.32356  0.40437  ...  0.12146  0.074369  0.87235  0.00000  1.5264   \n",
       "2  1.67620  0.69841  ...  0.16499  0.369210  0.81614  0.00000  4.3325   \n",
       "3  1.32410  0.32150  ...  0.29358  0.706570  0.78617  0.48456  5.2309   \n",
       "4  1.11260  0.52167  ...  0.10124  0.163790  0.89876  0.00000  5.7035   \n",
       "\n",
       "    Attr61   Attr62   Attr63   Attr64  class  \n",
       "0  5.16550  107.740  3.38790   5.3440   b'0'  \n",
       "1  0.63305  622.660  0.58619   1.2381   b'0'  \n",
       "2  3.19850   65.215  5.59690  47.4660   b'0'  \n",
       "3  5.06750  142.460  2.56210   3.0066   b'0'  \n",
       "4  4.00200   89.058  4.09840   5.9874   b'0'  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X1 net profit / total assets\n",
    "X2 total liabilities / total assets\n",
    "X3 working capital / total assets\n",
    "X4 current assets / short-term liabilities\n",
    "X5 [(cash + short-term securities + receivables - short-term liabilities) / (operating expenses - depreciation)] * 365\n",
    "X6 retained earnings / total assets\n",
    "X7 EBIT / total assets\n",
    "X8 book value of equity / total liabilities\n",
    "X9 sales / total assets\n",
    "X10 equity / total assets\n",
    "X11 (gross profit + extraordinary items + financial expenses) / total assets\n",
    "X12 gross profit / short-term liabilities\n",
    "X13 (gross profit + depreciation) / sales\n",
    "X14 (gross profit + interest) / total assets\n",
    "X15 (total liabilities * 365) / (gross profit + depreciation)\n",
    "X16 (gross profit + depreciation) / total liabilities\n",
    "X17 total assets / total liabilities\n",
    "X18 gross profit / total assets\n",
    "X19 gross profit / sales\n",
    "X20 (inventory * 365) / sales\n",
    "X21 sales (n) / sales (n-1)\n",
    "X22 profit on operating activities / total assets\n",
    "X23 net profit / sales\n",
    "X24 gross profit (in 3 years) / total assets\n",
    "X25 (equity - share capital) / total assets\n",
    "X26 (net profit + depreciation) / total liabilities\n",
    "X27 profit on operating activities / financial expenses\n",
    "X28 working capital / fixed assets\n",
    "X29 logarithm of total assets\n",
    "X30 (total liabilities - cash) / sales\n",
    "X31 (gross profit + interest) / sales\n",
    "X32 (current liabilities * 365) / cost of products sold\n",
    "X33 operating expenses / short-term liabilities\n",
    "X34 operating expenses / total liabilities\n",
    "X35 profit on sales / total assets\n",
    "X36 total sales / total assets\n",
    "X37 (current assets - inventories) / long-term liabilities\n",
    "X38 constant capital / total assets\n",
    "X39 profit on sales / sales\n",
    "X40 (current assets - inventory - receivables) / short-term liabilities\n",
    "X41 total liabilities / ((profit on operating activities + depreciation) * (12/365))\n",
    "X42 profit on operating activities / sales\n",
    "X43 rotation receivables + inventory turnover in days\n",
    "X44 (receivables * 365) / sales\n",
    "X45 net profit / inventory\n",
    "X46 (current assets - inventory) / short-term liabilities\n",
    "X47 (inventory * 365) / cost of products sold\n",
    "X48 EBITDA (profit on operating activities - depreciation) / total assets\n",
    "X49 EBITDA (profit on operating activities - depreciation) / sales\n",
    "X50 current assets / total liabilities\n",
    "X51 short-term liabilities / total assets\n",
    "X52 (short-term liabilities * 365) / cost of products sold)\n",
    "X53 equity / fixed assets\n",
    "X54 constant capital / fixed assets\n",
    "X55 working capital\n",
    "X56 (sales - cost of products sold) / sales\n",
    "X57 (current assets - inventory - short-term liabilities) / (sales - gross profit - depreciation)\n",
    "X58 total costs /total sales\n",
    "X59 long-term liabilities / equity\n",
    "X60 sales / inventory\n",
    "X61 sales / receivables\n",
    "X62 (short-term liabilities *365) / sales\n",
    "X63 sales / short-term liabilities\n",
    "X64 sales / fixed assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 43405 entries, 0 to 7026\n",
      "Data columns (total 65 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Attr1   43397 non-null  float64\n",
      " 1   Attr2   43397 non-null  float64\n",
      " 2   Attr3   43397 non-null  float64\n",
      " 3   Attr4   43271 non-null  float64\n",
      " 4   Attr5   43316 non-null  float64\n",
      " 5   Attr6   43397 non-null  float64\n",
      " 6   Attr7   43397 non-null  float64\n",
      " 7   Attr8   43311 non-null  float64\n",
      " 8   Attr9   43396 non-null  float64\n",
      " 9   Attr10  43397 non-null  float64\n",
      " 10  Attr11  43361 non-null  float64\n",
      " 11  Attr12  43271 non-null  float64\n",
      " 12  Attr13  43278 non-null  float64\n",
      " 13  Attr14  43397 non-null  float64\n",
      " 14  Attr15  43369 non-null  float64\n",
      " 15  Attr16  43310 non-null  float64\n",
      " 16  Attr17  43311 non-null  float64\n",
      " 17  Attr18  43397 non-null  float64\n",
      " 18  Attr19  43277 non-null  float64\n",
      " 19  Attr20  43278 non-null  float64\n",
      " 20  Attr21  37551 non-null  float64\n",
      " 21  Attr22  43397 non-null  float64\n",
      " 22  Attr23  43278 non-null  float64\n",
      " 23  Attr24  42483 non-null  float64\n",
      " 24  Attr25  43397 non-null  float64\n",
      " 25  Attr26  43310 non-null  float64\n",
      " 26  Attr27  40641 non-null  float64\n",
      " 27  Attr28  42593 non-null  float64\n",
      " 28  Attr29  43397 non-null  float64\n",
      " 29  Attr30  43278 non-null  float64\n",
      " 30  Attr31  43278 non-null  float64\n",
      " 31  Attr32  43037 non-null  float64\n",
      " 32  Attr33  43271 non-null  float64\n",
      " 33  Attr34  43311 non-null  float64\n",
      " 34  Attr35  43397 non-null  float64\n",
      " 35  Attr36  43397 non-null  float64\n",
      " 36  Attr37  24421 non-null  float64\n",
      " 37  Attr38  43397 non-null  float64\n",
      " 38  Attr39  43278 non-null  float64\n",
      " 39  Attr40  43271 non-null  float64\n",
      " 40  Attr41  42651 non-null  float64\n",
      " 41  Attr42  43278 non-null  float64\n",
      " 42  Attr43  43278 non-null  float64\n",
      " 43  Attr44  43278 non-null  float64\n",
      " 44  Attr45  41258 non-null  float64\n",
      " 45  Attr46  43270 non-null  float64\n",
      " 46  Attr47  43108 non-null  float64\n",
      " 47  Attr48  43396 non-null  float64\n",
      " 48  Attr49  43278 non-null  float64\n",
      " 49  Attr50  43311 non-null  float64\n",
      " 50  Attr51  43397 non-null  float64\n",
      " 51  Attr52  43104 non-null  float64\n",
      " 52  Attr53  42593 non-null  float64\n",
      " 53  Attr54  42593 non-null  float64\n",
      " 54  Attr55  43404 non-null  float64\n",
      " 55  Attr56  43278 non-null  float64\n",
      " 56  Attr57  43398 non-null  float64\n",
      " 57  Attr58  43321 non-null  float64\n",
      " 58  Attr59  43398 non-null  float64\n",
      " 59  Attr60  41253 non-null  float64\n",
      " 60  Attr61  43303 non-null  float64\n",
      " 61  Attr62  43278 non-null  float64\n",
      " 62  Attr63  43271 non-null  float64\n",
      " 63  Attr64  42593 non-null  float64\n",
      " 64  class   43405 non-null  object \n",
      "dtypes: float64(64), object(1)\n",
      "memory usage: 21.9+ MB\n"
     ]
    }
   ],
   "source": [
    "full_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'0'    41314\n",
       "b'1'     2091\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'0', b'1']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = []\n",
    "uniqueClass = full_df['class'].unique()\n",
    "classes.append(uniqueClass[0])\n",
    "classes.append(uniqueClass[1])\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'0': 0, b'1': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict = {}\n",
    "\n",
    "for index, i in enumerate(classes):\n",
    "    class_dict.update({i:index})\n",
    "\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['class'] = full_df['class'].map(class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    41314\n",
       "1     2091\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = full_df.loc[:, full_df.columns != 'class'].values\n",
    "y = full_df['class'].values\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imp_mean = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
    "imp_mean.fit(X_train)\n",
    "\n",
    "X_train = imp_mean.transform(X_train)\n",
    "X_test = imp_mean.transform(X_test)\n",
    "cols = full_df.columns.values.tolist()\n",
    "cols.remove('class')\n",
    "X_train = pd.DataFrame(X_train, columns=cols)\n",
    "X_test = pd.DataFrame(X_test, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=58)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=58)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=58)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf1 = RandomForestClassifier(random_state = 58)\n",
    "rf_clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 58,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf1.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      " [[28894     0]\n",
      " [    0  1489]]\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0   1.000000  1.000000  1.000000     28894\n",
      "           1   1.000000  1.000000  1.000000      1489\n",
      "\n",
      "    accuracy                       1.000000     30383\n",
      "   macro avg   1.000000  1.000000  1.000000     30383\n",
      "weighted avg   1.000000  1.000000  1.000000     30383\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat_rf_train1 = rf_clf1.predict(X_train)\n",
    "print(\"Confusion Matrix \\n\",confusion_matrix(y_train, y_hat_rf_train1))\n",
    "print(\"\\n Classification Report \\n\",classification_report(y_train, y_hat_rf_train1, digits=6))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "23da7f6e05bebdaf2be04501d041eb61ba6729cc62c1234a73c5754dfe472642"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
